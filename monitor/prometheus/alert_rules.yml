groups:
  - name: nexusml-critical-alerts
    rules:
    # Model Service Down
    - alert: ModelServiceDown
      expr: up{job="nexusml-backend"} == 0
      for: 1m
      labels:
        severity: critical
        team: mlops
      annotations:
        summary: "NexusML backend service is down"
        description: "The ML backend service has been down for more than 1 minute"
        runbook_url: "https://docs.nexusml.com/runbooks/service-down"

    # High Model Prediction Error Rate
    - alert: HighModelErrorRate
      expr: rate(model_prediction_errors_total[5m]) > 0.1
      for: 5m
      labels:
        severity: critical
        team: mlops
      annotations:
        summary: "High error rate detected in model predictions"
        description: "Model error rate is {{ $value }} errors/sec, above threshold of 0.1"

    # Model Load Failures
    - alert: ModelLoadFailures
      expr: increase(model_load_failure_total[10m]) > 0
      for: 2m
      labels:
        severity: critical
        team: mlops
      annotations:
        summary: "Model loading failures detected"
        description: "{{ $value }} model load failures in the last 10 minutes"

    # Redis Connection Lost
    - alert: RedisConnectionDown
      expr: infra_redis_connected == 0
      for: 1m
      labels:
        severity: critical
        team: mlops
      annotations:
        summary: "Redis connection is down"
        description: "Lost connection to Redis for more than 1 minute"

    # MinIO Connection Lost
    - alert: MinIOConnectionDown
      expr: infra_minio_connected == 0
      for: 1m
      labels:
        severity: critical
        team: mlops
      annotations:
        summary: "MinIO connection is down"
        description: "Lost connection to MinIO storage for more than 1 minute"

  - name: nexusml-warning-alerts
    rules:
    # High Model Latency (P95 > 2 seconds)
    - alert: HighModelLatency
      expr: histogram_quantile(0.95, rate(model_prediction_latency_seconds_bucket[5m])) > 2
      for: 10m
      labels:
        severity: warning
        team: mlops
      annotations:
        summary: "Model prediction latency is high"
        description: "95th percentile latency is {{ $value }}s, above threshold of 2s"

    # Low Model Confidence
    - alert: LowModelConfidence
      expr: avg_over_time(model_sentiment_confidence_score[1h]) < 0.6
      for: 30m
      labels:
        severity: warning
        team: mlops
      annotations:
        summary: "Model confidence scores are low"
        description: "Average confidence score is {{ $value }}, below threshold of 0.6"

    # High Memory Usage
    - alert: HighMemoryUsage
      expr: system_memory_usage_bytes / 1024 / 1024 / 1024 > 8
      for: 10m
      labels:
        severity: warning
        team: mlops
      annotations:
        summary: "High memory usage detected"
        description: "Memory usage is {{ $value }}GB, above threshold of 8GB"

    # High CPU Usage
    - alert: HighCPUUsage
      expr: system_cpu_usage_percent > 80
      for: 15m
      labels:
        severity: warning
        team: mlops
      annotations:
        summary: "High CPU usage detected"
        description: "CPU usage is {{ $value }}%, above threshold of 80%"

    # Batch Processing Failures
    - alert: HighBatchProcessingFailureRate
      expr: rate(batch_processing_count_total{status="failed"}[5m]) / rate(batch_processing_count_total[5m]) > 0.05
      for: 15m
      labels:
        severity: warning
        team: mlops
      annotations:
        summary: "High batch processing failure rate"
        description: "Batch processing failure rate is {{ $value | humanizePercentage }}, above threshold of 5%"

    # Sentiment Model Performance Degradation
    - alert: SentimentModelSlow
      expr: rate(model_sentiment_prediction_count[5m]) < 1
      for: 10m
      labels:
        severity: warning
        team: mlops
      annotations:
        summary: "Sentiment model throughput is low"
        description: "Sentiment predictions rate is {{ $value }} predictions/sec, below threshold of 1/sec"

    # Email Model Spam Detection Issues
    - alert: EmailModelSpamDetectionIssues
      expr: rate(model_email_spam_detected_total[5m]) / (rate(model_email_spam_detected_total[5m]) + rate(model_email_ham_detected_total[5m])) < 0.1
      for: 30m
      labels:
        severity: warning
        team: mlops
      annotations:
        summary: "Abnormal email spam detection pattern"
        description: "Spam detection rate is {{ $value | humanizePercentage }}, unusually low"

    # RecSys Cold Start Rate High
    - alert: RecSysHighColdStartRate
      expr: rate(model_recsys_cold_start_total[5m]) / rate(model_recsys_predictions_total[5m]) > 0.5
      for: 20m
      labels:
        severity: warning
        team: mlops
      annotations:
        summary: "High cold start rate in recommendation system"
        description: "Cold start rate is {{ $value | humanizePercentage }}, above threshold of 50%"

  - name: nexusml-infrastructure-alerts
    rules:
    # High API Request Rate (potential DDoS)
    - alert: HighAPIRequestRate
      expr: rate(api_request_count_total[5m]) > 100
      for: 5m
      labels:
        severity: warning
        team: mlops
      annotations:
        summary: "High API request rate detected"
        description: "API request rate is {{ $value }} requests/sec, above threshold of 100/sec"

    # High API Error Rate
    - alert: HighAPIErrorRate
      expr: rate(api_request_count_total{status=~"5.."}[5m]) / rate(api_request_count_total[5m]) > 0.05
      for: 10m
      labels:
        severity: warning
        team: mlops
      annotations:
        summary: "High API error rate"
        description: "API error rate is {{ $value | humanizePercentage }}, above threshold of 5%"

    # Model Load Time Too High
    - alert: HighModelLoadTime
      expr: rate(model_load_duration_seconds_sum[5m]) / rate(model_load_duration_seconds_count[5m]) > 30
      for: 15m
      labels:
        severity: warning
        team: mlops
      annotations:
        summary: "Model loading time is too high"
        description: "Average model load time is {{ $value }}s, above threshold of 30s"

    # Prometheus Configuration Issues
    - alert: PrometheusConfigurationError
      expr: prometheus_config_last_reload_successful == 0
      for: 5m
      labels:
        severity: critical
        team: sre
      annotations:
        summary: "Prometheus configuration reload failed"
        description: "Prometheus configuration has not been reloaded successfully"

  - name: nexusml-business-alerts
    rules:
    # Sentiment Analysis Trend Anomaly
    - alert: SentimentTrendAnomaly
      expr: abs(rate(model_sentiment_prediction_count{sentiment_label="negative"}[1h]) - rate(model_sentiment_prediction_count{sentiment_label="negative"}[2h] offset 1h)) > 0.5
      for: 30m
      labels:
        severity: warning
        team: analytics
      annotations:
        summary: "Unusual sentiment analysis trend detected"
        description: "Significant change in negative sentiment analysis patterns"

    # Topic Classification Imbalance
    - alert: TopicClassificationImbalance
      expr: (model_topic_prediction_count - ignoring(topic_label) group_left avg(model_topic_prediction_count)) / avg(model_topic_prediction_count) > 2
      for: 1h
      labels:
        severity: warning
        team: analytics
      annotations:
        summary: "Topic classification imbalance detected"
        description: "Unusual distribution in topic classification results"

    # RecSys Rating Distribution Issues
    - alert: RecSysRatingDistributionAnomaly
      expr: abs(rate(model_recsys_predicted_rating_sum[1h]) / rate(model_recsys_predicted_rating_count[1h]) - 3.0) > 1.0
      for: 30m
      labels:
        severity: warning
        team: analytics
      annotations:
        summary: "Recommendation rating distribution anomaly"
        description: "Average predicted rating deviates significantly from normal range of 3.0"
