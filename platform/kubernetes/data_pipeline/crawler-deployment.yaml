apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-pipeline-crawler
  namespace: nexusml # Assuming a namespace for the project
spec:
  replicas: 1 # Adjust as needed
  selector:
    matchLabels:
      app: data-pipeline-crawler
  template:
    metadata:
      labels:
        app: data-pipeline-crawler
    spec:
      containers:
      - name: crawler
        image: your-docker-repo/data-pipeline-crawler:latest # Replace with actual image name
        command: ["python", "-m", "crawler.main"] # Command to run the crawler
        env:
        # Add environment variables needed for the crawler
        # e.g., Kafka broker address, topic name
        - name: KAFKA_BROKERS
          value: "kafka-service.nexusml.svc.cluster.local:9092"
        - name: KAFKA_TOPIC
          value: "image-raw-data"
        # Add other necessary environment variables or config mounts
      # If the crawler needs persistent storage (e.g., for downloaded images before upload), add volumes here
      # volumes:
      # - name: crawler-storage
      #   persistentVolumeClaim:
      #     claimName: crawler-storage-pvc
